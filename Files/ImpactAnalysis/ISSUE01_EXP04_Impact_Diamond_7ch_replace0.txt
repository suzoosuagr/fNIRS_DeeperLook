++++++++++++++++++++mask: [(0, 1), (1, 0), (1, 2), (2, 1), (3, 0), (3, 2), (4, 1)]
ACCURACY_wml = 0.7584438131313131
Precisionwml = [0.84799362 0.68882779 0.74653627]
Recall_wml = [0.7836444  0.6430238  0.84932777]
F1_wml = [0.8145501  0.66513817 0.79462156]
Drop_WML: accu        -0.01685618686868684
Drop_WML: precision   -0.012980772506527072
Drop_WML: recall      -0.017834676916569703
Drop_WML: recall      -0.016096726304817843
ACCURACY_vpl = 0.7630997474747475
Precisionvpl = [0.73923493 0.86172507 0.70093222]
Recall_vpl = [0.85558646 0.78511788 0.64909006]
F1_vpl = [0.79316643 0.82163968 0.67401575]
Drop_VPL: accu        -0.009900252525252506
Drop_VPL: precision   -0.004902592990781995
Drop_VPL: recall      -0.010935199488398495
Drop_VPL: recall      -0.011159378928555008
++++++++++++++++++++mask: [(0, 3), (1, 2), (1, 4), (2, 3), (3, 2), (3, 4), (4, 3)]
ACCURACY_wml = 0.7496054292929293
Precisionwml = [0.86589823 0.66764061 0.73422524]
Recall_wml = [0.75638507 0.63975735 0.85234121]
F1_wml = [0.80744527 0.65340164 0.78888651]
Drop_WML: accu        -0.025694570707070707
Drop_WML: precision   -0.018178639317431577
Drop_WML: recall      -0.0270054556925704
Drop_WML: recall      -0.024288858706930205
ACCURACY_vpl = 0.749447601010101
Precisionvpl = [0.72793538 0.86996025 0.67206676]
Recall_vpl = [0.85651368 0.7524558  0.63882408]
F1_vpl = [0.78700745 0.80695286 0.65502392]
Drop_VPL: accu        -0.023552398989899026
Drop_VPL: precision   -0.015545867700331173
Drop_VPL: recall      -0.02493548317500538
Drop_VPL: recall      -0.02443858809894872
++++++++++++++++++++mask: [(0, 5), (1, 4), (1, 6), (2, 5), (3, 4), (3, 6), (4, 5)]
ACCURACY_wml = 0.7447916666666666
Precisionwml = [0.86292391 0.67485869 0.71927758]
Recall_wml = [0.74361493 0.64069062 0.84932777]
F1_wml = [0.7988392  0.65733094 0.77891156]
Drop_WML: accu        -0.03050833333333336
Drop_WML: precision   -0.02174660698250397
Drop_WML: recall      -0.03195555936199679
Drop_WML: recall      -0.02917276418188719
ACCURACY_vpl = 0.7425031565656566
Precisionvpl = [0.71068335 0.87313651 0.67307692]
Recall_vpl = [0.85581827 0.73354617 0.63695754]
F1_vpl = [0.7765275  0.79727746 0.6545193 ]
Drop_VPL: accu        -0.030496843434343446
Drop_VPL: precision   -0.01990107258540663
Drop_VPL: recall      -0.03209267625555434
Drop_VPL: recall      -0.03132524694910621
++++++++++++++++++++mask: [(0, 7), (1, 6), (1, 8), (2, 7), (3, 6), (3, 8), (4, 7)]
ACCURACY_wml = 0.7434501262626263
Precisionwml = [0.85477062 0.67623252 0.7193574 ]
Recall_wml = [0.74582515 0.64325712 0.84075104]
F1_wml = [0.79659016 0.65933278 0.77533134]
Drop_WML: accu        -0.03184987373737369
Drop_WML: precision   -0.023979820615613545
Drop_WML: recall      -0.03322223111485567
Drop_WML: recall      -0.030448574189001154
ACCURACY_vpl = 0.7411616161616161
Precisionvpl = [0.71076146 0.86451427 0.67422935]
Recall_vpl = [0.84816875 0.73649312 0.63789081]
F1_vpl = [0.77340943 0.79538523 0.65555689]
Drop_VPL: accu        -0.03183838383838389
Drop_VPL: precision   -0.02236497450362085
Drop_VPL: recall      -0.03334910535028002
Drop_VPL: recall      -0.032649485910272724
++++++++++++++++++++mask: [(0, 9), (1, 8), (1, 10), (2, 9), (3, 8), (3, 10), (4, 9)]
ACCURACY_wml = 0.7474747474747475
Precisionwml = [0.8542865  0.68219895 0.72043838]
Recall_wml = [0.76596267 0.60802613 0.86856745]
F1_wml = [0.80771721 0.64298051 0.78759853]
Drop_WML: accu        -0.027825252525252475
Drop_WML: precision   -0.021792057678364674
Drop_WML: recall      -0.028981247234914687
Drop_WML: recall      -0.028101251585599396
ACCURACY_vpl = 0.7475536616161617
Precisionvpl = [0.71493556 0.86474501 0.6813622 ]
Recall_vpl = [0.87436254 0.76620825 0.60219319]
F1_vpl = [0.78665276 0.8125     0.63933614]
Drop_VPL: accu        -0.025446338383838363
Drop_VPL: precision   -0.018519078421159074
Drop_VPL: recall      -0.02661200694668786
Drop_VPL: recall      -0.027937032002120832
++++++++++++++++++++mask: [(0, 11), (1, 10), (1, 12), (2, 11), (3, 10), (3, 12), (4, 11)]
ACCURACY_wml = 0.7556818181818182
Precisionwml = [0.86279324 0.69086826 0.72909164]
Recall_wml = [0.77676817 0.64605693 0.8446917 ]
F1_wml = [0.81752391 0.6677116  0.78264605]
Drop_WML: accu        -0.019618181818181757
Drop_WML: precision   -0.01318228824620793
Drop_WML: recall      -0.020661065378923982
Drop_WML: recall      -0.018239481719131145
ACCURACY_vpl = 0.7514993686868687
Precisionvpl = [0.71355196 0.87214737 0.68940347]
Recall_vpl = [0.83727399 0.77897839 0.6390574 ]
F1_vpl = [0.77047782 0.82293423 0.66327643]
Drop_VPL: accu        -0.02150063131313129
Drop_VPL: precision   -0.01383239886533727
Drop_VPL: recall      -0.022430074391099897
Drop_VPL: recall      -0.021870508622644502
++++++++++++++++++++mask: [(0, 13), (1, 12), (1, 14), (2, 13), (3, 12), (3, 14), (4, 13)]
ACCURACY_wml = 0.7539457070707071
Precisionwml = [0.84066524 0.68782288 0.74277516]
Recall_wml = [0.76964637 0.65235651 0.84005563]
F1_wml = [0.80358974 0.6696204  0.78842598]
Drop_WML: accu        -0.021354292929292917
Drop_WML: precision   -0.017012242291896684
Drop_WML: recall      -0.0224804973960695
Drop_WML: recall      -0.02032129179400155
ACCURACY_vpl = 0.7557607323232324
Precisionvpl = [0.73301069 0.85030906 0.69589178]
Recall_vpl = [0.84260547 0.77701375 0.64815679]
F1_vpl = [0.78399655 0.81201078 0.67117661]
Drop_VPL: accu        -0.017239267676767644
Drop_VPL: precision   -0.012462824029680797
Drop_VPL: recall      -0.018274662478625525
Drop_VPL: recall      -0.01837201975545566
++++++++++++++++++++mask: [(0, 15), (1, 14), (1, 16), (2, 15), (3, 14), (3, 16), (4, 15)]
ACCURACY_wml = 0.7493686868686869
Precisionwml = [0.864612   0.6781491  0.72183372]
Recall_wml = [0.771611   0.6154923  0.86138155]
F1_wml = [0.81546847 0.64530333 0.78545762]
Drop_WML: accu        -0.02593131313131314
Drop_WML: precision   -0.019235060036879803
Drop_WML: recall      -0.027005049691715688
Drop_WML: recall      -0.025456862368679167
ACCURACY_vpl = 0.7404513888888888
Precisionvpl = [0.70697585 0.86915367 0.66597618]
Recall_vpl = [0.85512286 0.76669941 0.60009333]
F1_vpl = [0.77402434 0.81471816 0.63132057]
Drop_VPL: accu        -0.03254861111111118
Drop_VPL: precision   -0.024831431401276083
Drop_VPL: recall      -0.03356146882039024
Drop_VPL: recall      -0.03407897620915035
++++++++++++++++++++mask: [(0, 17), (1, 16), (1, 18), (2, 17), (3, 16), (3, 18), (4, 17)]
ACCURACY_wml = 0.7526041666666666
Precisionwml = [0.85614973 0.67607053 0.73579202]
Recall_wml = [0.78634578 0.62622492 0.84631433]
F1_wml = [0.81976446 0.6501938  0.78719276]
Drop_WML: accu        -0.02269583333333336
Drop_WML: precision   -0.018095906355129032
Drop_WML: recall      -0.02353832672592382
Drop_WML: recall      -0.02181632704219083
ACCURACY_vpl = 0.7476325757575758
Precisionvpl = [0.72631579 0.86767538 0.66541729]
Recall_vpl = [0.84770515 0.77455796 0.62132524]
F1_vpl = [0.78232966 0.81847671 0.64261583]
Drop_VPL: accu        -0.02536742424242422
Drop_VPL: precision   -0.019063846968381037
Drop_VPL: recall      -0.02633721740072492
Drop_VPL: recall      -0.026292599824327967
++++++++++++++++++++mask: [(0, 19), (1, 18), (1, 20), (2, 19), (3, 18), (3, 20), (4, 19)]
ACCURACY_wml = 0.7630997474747475
Precisionwml = [0.83967322 0.69601838 0.75542692]
Recall_wml = [0.8077112  0.63625758 0.84700974]
F1_wml = [0.82338215 0.66479766 0.79860125]
Drop_WML: accu        -0.012200252525252475
Drop_WML: precision   -0.010393828821947837
Drop_WML: recall      -0.012840494333269503
Drop_WML: recall      -0.011939648033141848
ACCURACY_vpl = 0.7596275252525253
Precisionvpl = [0.73778765 0.84937238 0.69928095]
Recall_vpl = [0.84724154 0.79764244 0.63532431]
F1_vpl = [0.78873543 0.82269504 0.66577017]
Drop_VPL: accu        -0.013372474747474716
Drop_VPL: precision   -0.010053007890905907
Drop_VPL: recall      -0.01413057098778514
Drop_VPL: recall      -0.015033119879774515
