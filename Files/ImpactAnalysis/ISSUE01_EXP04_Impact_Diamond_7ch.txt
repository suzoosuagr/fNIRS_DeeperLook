++++++++++++++++++++mask: [(0, 1), (1, 0), (1, 2), (2, 1), (3, 0), (3, 2), (4, 1)]
ACCURACY_wml = 0.7702809343434344
Precisionwml = [0.83688299 0.70561571 0.76836518]
Recall_wml = [0.82023576 0.65375642 0.83889662]
F1_wml = [0.82847575 0.67869686 0.80208333]
Drop_WML: accu        -0.005019065656565624
Drop_WML: precision   -0.0038120396289417213
Drop_WML: recall      -0.005537070568700564
Drop_WML: recall      -0.004448016652496389
ACCURACY_vpl = 0.7747001262626263
Precisionvpl = [0.76042535 0.85093956 0.71584561]
Recall_vpl = [0.84538711 0.82293713 0.65772282]
F1_vpl = [0.80065862 0.83670412 0.68555447]
Drop_VPL: accu        0.001700126262626278
Drop_VPL: precision   0.0035368415330591096
Drop_VPL: recall      0.0011490206128900171
Drop_VPL: recall      0.0002057371542864006
++++++++++++++++++++mask: [(0, 3), (1, 2), (1, 4), (2, 3), (3, 2), (3, 4), (4, 3)]
ACCURACY_wml = 0.7589962121212122
Precisionwml = [0.81865413 0.68732748 0.76856835]
Recall_wml = [0.81262279 0.6390574  0.82753825]
F1_wml = [0.81562731 0.66231411 0.79696395]
Drop_WML: accu        -0.016303787878787834
Drop_WML: precision   -0.01591667909050476
Drop_WML: recall      -0.01676052215881907
Drop_WML: recall      -0.01589821092359056
ACCURACY_vpl = 0.7595486111111112
Precisionvpl = [0.75036803 0.8391998  0.69128024]
Recall_vpl = [0.82707464 0.81385069 0.63999067]
F1_vpl = [0.78685632 0.82633088 0.66464744]
Drop_VPL: accu        -0.01345138888888886
Drop_VPL: precision   -0.011917308999552456
Drop_VPL: recall      -0.013894668127893528
Drop_VPL: recall      -0.014821783719959347
++++++++++++++++++++mask: [(0, 5), (1, 4), (1, 6), (2, 5), (3, 4), (3, 6), (4, 5)]
ACCURACY_wml = 0.7604166666666666
Precisionwml = [0.81747761 0.69568587 0.76359743]
Recall_wml = [0.8293222  0.62832478 0.82661103]
F1_wml = [0.82335731 0.66029177 0.79385574]
Drop_WML: accu        -0.01488333333333336
Drop_WML: precision   -0.015179697327147745
Drop_WML: recall      -0.015080662471887218
Drop_WML: recall      -0.015031724739194785
ACCURACY_vpl = 0.7622316919191919
Precisionvpl = [0.75141837 0.83826823 0.6969697 ]
Recall_vpl = [0.82892907 0.82735756 0.63322445]
F1_vpl = [0.7882729  0.83277716 0.66356968]
Drop_VPL: accu        -0.010768308080808087
Drop_VPL: precision   -0.009981237300227153
Drop_VPL: recall      -0.011029638765294614
Drop_VPL: recall      -0.012560086810976423
++++++++++++++++++++mask: [(0, 7), (1, 6), (1, 8), (2, 7), (3, 6), (3, 8), (4, 7)]
ACCURACY_wml = 0.7653882575757576
Precisionwml = [0.82008266 0.70490943 0.76652632]
Recall_wml = [0.82833988 0.62645824 0.84399629]
F1_wml = [0.82419059 0.66337245 0.80339806]
Drop_WML: accu        -0.00991174242424242
Drop_WML: precision   -0.010260531480989377
Drop_WML: recall      -0.010235196871830499
Drop_WML: recall      -0.010546299023095007
ACCURACY_vpl = 0.7687026515151515
Precisionvpl = [0.76063386 0.83341535 0.70986359]
Recall_vpl = [0.84561892 0.831778   0.63135791]
F1_vpl = [0.80087816 0.83259587 0.66831316]
Drop_VPL: accu        -0.004297348484848529
Drop_VPL: precision   -0.00422906515021082
Drop_VPL: recall      -0.004615059765542218
Drop_VPL: recall      -0.006837603392236269
++++++++++++++++++++mask: [(0, 9), (1, 8), (1, 10), (2, 9), (3, 8), (3, 10), (4, 9)]
ACCURACY_wml = 0.7571811868686869
Precisionwml = [0.81535119 0.69132253 0.7595152 ]
Recall_wml = [0.82956778 0.61712552 0.82800185]
F1_wml = [0.82239805 0.65212032 0.79228125]
Drop_WML: accu        -0.01811881313131314
Drop_WML: precision   -0.018703690698078868
Drop_WML: recall      -0.018268280215614996
Drop_WML: recall      -0.01860012851351589
ACCURACY_vpl = 0.7558396464646465
Precisionvpl = [0.74676949 0.82554441 0.69210457]
Recall_vpl = [0.83055169 0.82858546 0.6115259 ]
F1_vpl = [0.78643547 0.82706214 0.64932491]
Drop_VPL: accu        -0.0171603535353535
Drop_VPL: precision   -0.017393845117254503
Drop_VPL: recall      -0.017312315957306645
Drop_VPL: recall      -0.01982582670903965
++++++++++++++++++++mask: [(0, 11), (1, 10), (1, 12), (2, 11), (3, 10), (3, 12), (4, 11)]
ACCURACY_wml = 0.7610479797979798
Precisionwml = [0.82322863 0.6946045  0.76069096]
Recall_wml = [0.83030452 0.61875875 0.83704219]
F1_wml = [0.82675144 0.65449161 0.79704227]
Drop_WML: accu        -0.01425202020202021
Drop_WML: precision   -0.014591966090278463
Drop_WML: recall      -0.014464847898287059
Drop_WML: recall      -0.014771561748966211
ACCURACY_vpl = 0.7556029040404041
Precisionvpl = [0.74653137 0.82920792 0.68892979]
Recall_vpl = [0.83565137 0.82269155 0.61129258]
F1_vpl = [0.78858143 0.82593688 0.6477933 ]
Drop_VPL: accu        -0.017397095959595932
Drop_VPL: precision   -0.017310304661198872
Drop_VPL: recall      -0.017654833267419012
Drop_VPL: recall      -0.019996129471013036
++++++++++++++++++++mask: [(0, 13), (1, 12), (1, 14), (2, 13), (3, 12), (3, 14), (4, 13)]
ACCURACY_wml = 0.7621527777777778
Precisionwml = [0.83114632 0.68570716 0.76816609]
Recall_wml = [0.82441061 0.64139057 0.82336579]
F1_wml = [0.82776476 0.66280892 0.79480868]
Drop_WML: accu        -0.013147222222222199
Drop_WML: precision   -0.012426809264915684
Drop_WML: recall      -0.01344434372910197
Drop_WML: recall      -0.01240587767686041
ACCURACY_vpl = 0.7596275252525253
Precisionvpl = [0.75695181 0.83262975 0.68810371]
Recall_vpl = [0.82661103 0.82342829 0.63159123]
F1_vpl = [0.79024931 0.82800346 0.65863747]
Drop_VPL: accu        -0.013372474747474716
Drop_VPL: precision   -0.012971574890124571
Drop_VPL: recall      -0.013656482712991469
Drop_VPL: recall      -0.015136588572486898
++++++++++++++++++++mask: [(0, 15), (1, 14), (1, 16), (2, 15), (3, 14), (3, 16), (4, 15)]
ACCURACY_wml = 0.7571811868686869
Precisionwml = [0.8553751  0.67818683 0.74354167]
Recall_wml = [0.81483301 0.63182455 0.82730644]
F1_wml = [0.834612   0.65418529 0.7831907 ]
Drop_WML: accu        -0.01811881313131314
Drop_WML: precision   -0.0150654699039251
Drop_WML: recall      -0.018512001646795118
Drop_WML: recall      -0.01687067259929398
ACCURACY_vpl = 0.7582070707070707
Precisionvpl = [0.73729685 0.86072351 0.6833291 ]
Recall_vpl = [0.8307835  0.81802554 0.62832478]
F1_vpl = [0.78125341 0.83883153 0.65467364]
Drop_VPL: accu        -0.014792929292929302
Drop_VPL: precision   -0.011750176333458762
Drop_VPL: recall      -0.015155395260368576
Drop_VPL: recall      -0.015847143277699538
++++++++++++++++++++mask: [(0, 17), (1, 16), (1, 18), (2, 17), (3, 16), (3, 18), (4, 17)]
ACCURACY_wml = 0.765072601010101
Precisionwml = [0.84730691 0.69483806 0.75543478]
Recall_wml = [0.81900786 0.64069062 0.8377376 ]
F1_wml = [0.83291708 0.66666667 0.79446032]
Drop_WML: accu        -0.010227398989898995
Drop_WML: precision   -0.008240083380678831
Drop_WML: recall      -0.01068797410402711
Drop_WML: recall      -0.009518643155530415
ACCURACY_vpl = 0.7657039141414141
Precisionvpl = [0.74830491 0.85392107 0.69920574]
Recall_vpl = [0.84422809 0.81827112 0.63672422]
F1_vpl = [0.79337763 0.83571608 0.66650385]
Drop_VPL: accu        -0.007296085858585877
Drop_VPL: precision   -0.005056094694169233
Drop_VPL: recall      -0.0077921890653099846
Drop_VPL: recall      -0.008900816138671552
++++++++++++++++++++mask: [(0, 19), (1, 18), (1, 20), (2, 19), (3, 18), (3, 20), (4, 19)]
ACCURACY_wml = 0.7676767676767676
Precisionwml = [0.84528016 0.69962264 0.75987328]
Recall_wml = [0.82244597 0.64885674 0.83402874]
F1_wml = [0.83370675 0.67328411 0.79522599]
Drop_WML: accu        -0.007623232323232365
Drop_WML: precision   -0.005841304300359007
Drop_WML: recall      -0.008056180331899365
Drop_WML: recall      -0.00679438526972076
ACCURACY_vpl = 0.7683869949494949
Precisionvpl = [0.74793218 0.8581306  0.70440092]
Recall_vpl = [0.83843301 0.82293713 0.64605693]
F1_vpl = [0.79060109 0.84016548 0.6739686 ]
Drop_VPL: accu        -0.0046130050505051035
Drop_VPL: precision   -0.002045435686129804
Drop_VPL: recall      -0.0050576433409301735
Drop_VPL: recall      -0.005854943227206477
